# Sobre
RepositÃ³rio para armazenar estudos, projetos e materiais relacionados ao Mestrado em InformÃ¡tica na Universidade Federal de Alagoas (UFAL). Inclui cÃ³digos-fonte, documentos, apresentaÃ§Ãµes e outros recursos desenvolvidos durante o curso.

---  

# ğŸ“ **Projeto de Mestrado**  
## Universidade Federal de Alagoas (UFAL) - Instituto de ComputaÃ§Ã£o  
### Programa de PÃ³s-GraduaÃ§Ã£o em InformÃ¡tica  

## ğŸ“Œ **TÃ­tulo**  
**DetecÃ§Ã£o de VÃ­deos Criados ou Alterados por InteligÃªncia Artificial atravÃ©s de TÃ©cnicas AvanÃ§adas de VisÃ£o Computacional e Aprendizado de MÃ¡quina**  

ğŸ‘¨â€ğŸ“ **Aluno:** FÃ¡bio Santâ€™Anna Linhares  
ğŸ‘©â€ğŸ« **Orientadora:** Prof.Âª Dr.Âª Fabiane da Silva Queiroz  
ğŸ”¬ **Linha de Pesquisa:** ComputaÃ§Ã£o Visual e Inteligente  

---

## ğŸ“ **Resumo**  

A crescente disseminaÃ§Ã£o de **mÃ­dias sintÃ©ticas**, criadas ou alteradas por InteligÃªncia Artificial (IA), representa um grande desafio para a **seguranÃ§a da informaÃ§Ã£o** e a **veracidade dos conteÃºdos online**. A capacidade dessas tecnologias de gerar vÃ­deos altamente realistas e convincentes torna difÃ­cil distinguir conteÃºdos autÃªnticos de falsificaÃ§Ãµes, levando a implicaÃ§Ãµes sociais, polÃ­ticas e jurÃ­dicas.  

Este projeto busca aprimorar as tÃ©cnicas de **detecÃ§Ã£o de vÃ­deos manipulados** por IA, combinando **visÃ£o computacional** e **aprendizado de mÃ¡quina**. A metodologia baseia-se na abordagem proposta por **Rafique et al. (2023)**, que utiliza **AnÃ¡lise de NÃ­vel de Erro (ELA) e Redes Neurais Convolucionais (CNNs)** para identificar alteraÃ§Ãµes digitais. No entanto, nosso trabalho avanÃ§a essa abordagem ao integrar tÃ©cnicas de **anÃ¡lise de textura** e regras especializadas de **detecÃ§Ã£o forense**.  

O objetivo Ã© desenvolver uma estrutura de detecÃ§Ã£o capaz de superar a **precisÃ£o de 89,5%** dos mÃ©todos existentes, contribuindo significativamente para a mitigaÃ§Ã£o dos desafios impostos pelas mÃ­dias sintÃ©ticas.  

---

## ğŸ¯ **Objetivos do Projeto**  

O projeto visa desenvolver uma estrutura eficiente para **detecÃ§Ã£o e classificaÃ§Ã£o de mÃ­dias sintÃ©ticas em vÃ­deos**, utilizando tÃ©cnicas de visÃ£o computacional e aprendizado de mÃ¡quina.  

### ğŸ”¹ **Objetivos EspecÃ­ficos**  
âœ” **Identificar e classificar tÃ©cnicas de detecÃ§Ã£o** de mÃ­dias sintÃ©ticas.  
âœ” **Compilar e combinar mÃºltiplos mÃ©todos** para aprimorar a detecÃ§Ã£o.  
âœ” **Utilizar CNNs prÃ©-treinadas** (GoogLeNet, ResNet18, SqueezeNet) para extrair padrÃµes visuais de vÃ­deos manipulados.  
âœ” **Implementar AnÃ¡lise de NÃ­vel de Erro (ELA)** para identificar regiÃµes manipuladas digitalmente.  
âœ” **Testar diversos algoritmos de classificaÃ§Ã£o** (SVM, Random Forest, XGBoost, MLP, entre outros) para avaliar a eficÃ¡cia das tÃ©cnicas.  
âœ” **Aprimorar a precisÃ£o de detecÃ§Ã£o**, superando os 89,5% alcanÃ§ados pelos mÃ©todos anteriores.  

---

## ğŸ“š **Justificativa**  

O avanÃ§o das tecnologias de geraÃ§Ã£o de vÃ­deos sintÃ©ticos levou Ã  criaÃ§Ã£o de deepfakes **quase indistinguÃ­veis da realidade**. Segundo **Rodrigues et al. (2024)**, esses conteÃºdos tÃªm sido usados para manipulaÃ§Ã£o polÃ­tica, disseminaÃ§Ã£o de desinformaÃ§Ã£o e crimes cibernÃ©ticos.  

Estudos como o de **Vahdati et al. (2024)** e **Xu et al. (2024)** demonstram que detectores atuais sÃ£o **menos eficazes para vÃ­deos do que para imagens**. Modelos tradicionais de CNNs sÃ£o eficientes na detecÃ§Ã£o de deepfakes em imagens, mas falham na anÃ¡lise de padrÃµes temporais presentes em vÃ­deos.  

AlÃ©m disso, segundo **Pei et al. (2024)**, os **modelos de difusÃ£o** emergiram como uma tecnologia revolucionÃ¡ria para geraÃ§Ã£o de deepfakes, exigindo o aprimoramento dos mÃ©todos de detecÃ§Ã£o. Este projeto propÃµe uma abordagem inovadora que combina **anÃ¡lise de padrÃµes texturais, ELA e redes neurais profundas**, aumentando a robustez do processo de detecÃ§Ã£o.  

---

## ğŸ›  **Metodologia**  

A pesquisa serÃ¡ baseada em um conjunto de **etapas experimentais**, conforme descrito abaixo:  

### **1ï¸âƒ£ SeleÃ§Ã£o de Dados**  
- Uso de bases pÃºblicas, como **FaceForensics++ (FF++)**, contendo vÃ­deos reais e manipulados.  
- AplicaÃ§Ã£o de prÃ©-processamento para padronizar a qualidade dos vÃ­deos.  

### **2ï¸âƒ£ ExtraÃ§Ã£o de CaracterÃ­sticas**  
- Uso de **CNNs prÃ©-treinadas (GoogLeNet, ResNet18, SqueezeNet)** para extrair caracterÃ­sticas de alto nÃ­vel.  
- ImplementaÃ§Ã£o da **AnÃ¡lise de NÃ­vel de Erro (ELA)** para identificar padrÃµes anÃ´malos.  
- AplicaÃ§Ã£o de **anÃ¡lise de textura** para capturar artefatos gerados por IA.  

### **3ï¸âƒ£ Treinamento de Modelos**  
- Treinamento de modelos de classificaÃ§Ã£o como **SVM, Random Forest, XGBoost, LightGBM, MLP**.  
- OtimizaÃ§Ã£o dos hiperparÃ¢metros para melhorar a precisÃ£o e reduzir falsos positivos.  

### **4ï¸âƒ£ ValidaÃ§Ã£o e AvaliaÃ§Ã£o**  
- Testes com conjuntos de dados independentes para validar a eficÃ¡cia do modelo.  
- Uso de mÃ©tricas como **precisÃ£o, recall e F1-score** para avaliaÃ§Ã£o do desempenho.  

---

## ğŸ“ˆ **Resultados Esperados**  

Espera-se que o modelo desenvolvido atinja **uma precisÃ£o superior a 89,5%**, fornecendo uma abordagem mais eficaz para a **detecÃ§Ã£o de deepfakes em vÃ­deos**. Os principais benefÃ­cios incluem:  

âœ” **Aprimoramento da detecÃ§Ã£o** de mÃ­dias sintÃ©ticas com novas tÃ©cnicas.  
âœ” **CriaÃ§Ã£o de um framework hÃ­brido** combinando diferentes mÃ©todos de anÃ¡lise.  
âœ” **ContribuiÃ§Ã£o para a seguranÃ§a da informaÃ§Ã£o**, reduzindo a disseminaÃ§Ã£o de vÃ­deos falsificados.  
âœ” **PublicaÃ§Ã£o dos resultados** em conferÃªncias e periÃ³dicos cientÃ­ficos.  

---

## ğŸ”¬ **ReferÃªncias**  

ğŸ“„ **Rafique, R. et al. (2023).** *Deep Fake Detection and Classification Using Error-Level Analysis and Deep Learning.* Scientific Reports. DisponÃ­vel em: [https://doi.org/10.1038/s41598-023-34629-3](https://doi.org/10.1038/s41598-023-34629-3)  

ğŸ“„ **Rodrigues, G. S. et al. (2024).** *Uma Abordagem a DeepFake via Algoritmos de Aprendizagem Profunda.* Anais do ENCOMPIF. DisponÃ­vel em: [https://sol.sbc.org.br/index.php/encompif/article/view/25238](https://sol.sbc.org.br/index.php/encompif/article/view/25238)  

ğŸ“„ **Pei, G. et al. (2024).** *Deepfake Generation and Detection: A Benchmark and Survey.* arXiv. DisponÃ­vel em: [https://arxiv.org/pdf/2403.17881](https://arxiv.org/pdf/2403.17881)  

ğŸ“„ **Vahdati, D. S. et al. (2024).** *Beyond Deepfake Images: Detecting AI-Generated Videos.* CVPR 2024 Workshops. DisponÃ­vel em: [https://openaccess.thecvf.com/content/CVPR2024W/WMF/papers/Vahdati](https://openaccess.thecvf.com/content/CVPR2024W/WMF/papers/Vahdati)  

ğŸ“„ **Xu, S. et al. (2024).** *VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time.* arXiv. DisponÃ­vel em: [https://arxiv.org/pdf/2404.10667](https://arxiv.org/pdf/2404.10667)  

---

## ğŸ“¬ **Contato**  
ğŸ“© **E-mail:** fl@ic.ufal.br  
ğŸ”— **LinkedIn:** [linkedin.com/in/fabio-linhares](https://www.linkedin.com/in/fabio-linhares)  
ğŸ™ **GitHub:** [github.com/fabio-linhares](https://github.com/fabio-linhares)  

