<div align="center">
  <img src="docs/img/logo.png" alt="Logo da UFAL" width="200"/>
</div>


# üéì **Projeto de Mestrado**  

Reposit√≥rio para armazenar estudos, projetos e materiais relacionados ao Mestrado em Inform√°tica na Universidade Federal de Alagoas (UFAL). Inclui c√≥digos-fonte, documentos, apresenta√ß√µes e outros recursos desenvolvidos durante o curso.


## Universidade Federal de Alagoas (UFAL) - Instituto de Computa√ß√£o  
### Programa de P√≥s-Gradua√ß√£o em Inform√°tica  

## üìå **T√≠tulo**  
**Detec√ß√£o Avan√ßada de M√≠dias Sint√©ticas em V√≠deos mediante An√°lise de Complexidade-Entropia**  

üë®‚Äçüéì **Aluno:** F√°bio Sant'Anna Linhares  
üë©‚Äçüè´ **Orientadora:** Prof.¬™ Dr.¬™ Fabiane da Silva Queiroz  
üî¨ **Linha de Pesquisa:** Computa√ß√£o Visual e Inteligente  
üéØ **Tema de Pesquisa:** Vis√£o Computacional: An√°lise, Caracteriza√ß√£o e Classifica√ß√£o de Padr√µes Din√¢micos e Estruturais em M√≠dias Sint√©ticas

---

## üìù **Introdu√ß√£o**  

A prolifera√ß√£o de **m√≠dias sint√©ticas**, popularmente conhecidas como deepfakes, representa um desafio crescente para a seguran√ßa da informa√ß√£o e a confian√ßa no ecossistema digital. A r√°pida evolu√ß√£o dos modelos generativos, como **Redes Adversariais Generativas (GANs)** e **Modelos de Difus√£o**, torna os m√©todos de detec√ß√£o baseados em artefatos espec√≠ficos rapidamente obsoletos. A comunidade de pesquisa enfrenta a necessidade premente de desenvolver detectores que n√£o apenas apresentem alta acur√°cia, mas que tamb√©m generalizem para m√©todos de manipula√ß√£o desconhecidos e n√£o vistos durante o treinamento.

A literatura atual √© dominada por abordagens de aprendizado profundo, como **Redes Neurais Convolucionais (CNNs)** e **Vision Transformers (ViTs)**, que, apesar de seu desempenho not√°vel, frequentemente operam como "caixas-pretas". Esses modelos podem aprender correla√ß√µes esp√∫rias nos dados de treinamento, o que limita sua robustez em cen√°rios do mundo real. Existe uma lacuna significativa na literatura no que tange a m√©todos de detec√ß√£o fundamentados em princ√≠pios te√≥ricos que explorem a natureza intr√≠nseca do conte√∫do gerado por IA.

### **üéØ Mudan√ßa de Paradigma Proposta**

Este projeto de pesquisa prop√µe uma **mudan√ßa de paradigma**. Em vez de tratar imagens geradas por IA como imagens aut√™nticas com defeitos, hipotetizamos que elas s√£o o produto de um **sistema din√¢mico complexo e determin√≠stico**. Argumentamos que tais sistemas imprimem uma **"textura estat√≠stica"** √∫nica e mensur√°vel, caracterizada por uma assinatura espec√≠fica no espa√ßo de complexidade-entropia, an√°loga √† de sistemas ca√≥ticos.

Propomos o **Plano Causalidade Entropia-Complexidade (Plano CH)** como a ferramenta principal para capturar essa assinatura fundamental, visando criar um detector que seja, por constru√ß√£o, mais generaliz√°vel e interpret√°vel. Esta abordagem combina a robustez te√≥rica da **Teoria da Informa√ß√£o** com a capacidade de representa√ß√£o dos modelos de **aprendizado profundo**, oferecendo uma solu√ß√£o h√≠brida e inovadora para o problema da detec√ß√£o de m√≠dias sint√©ticas.

---

## üìö **Justificativa**

A era da informa√ß√£o digital √© marcada por um fluxo massivo de conte√∫do cuja veracidade √© frequentemente questionada. Imagens e v√≠deos n√£o naturais ‚Äî ou seja, gerados parcial ou totalmente por algoritmos de intelig√™ncia artificial, contendo um ou mais rostos humanos trocados ou n√£o ‚Äî constituem um novo tipo de artefato comunicacional: o que chamaremos **produtos de IA**.

A populariza√ß√£o de algoritmos generativos, como as **Redes Adversariais Generativas (GANs)** e os **modelos de difus√£o**, tem permitido a cria√ß√£o de conte√∫do sint√©tico visualmente consistente, muitas vezes indistingu√≠vel, a olho nu, de conte√∫do natural e aut√™ntico. Isso levanta s√©rias preocupa√ß√µes sobre **desinforma√ß√£o**, **manipula√ß√£o de opini√£o p√∫blica** e **danos √† imagem pessoal e coletiva**.

### **Limita√ß√µes das Abordagens Atuais**

Pesquisas voltadas √† detec√ß√£o desses produtos sint√©ticos concentradas, em grande parte, em abordagens baseadas em **Deep Learning (DL)**, como Redes Neurais Convolucionais (CNNs) e Vision Transformers (ViTs) t√™m demonstrado resultados promissores. No entanto, muitos desses m√©todos se concentram na an√°lise de artefatos espaciais e na detec√ß√£o de anomalias em quadros individuais.

A **natureza temporal dos v√≠deos**, onde a evolu√ß√£o dos padr√µes e correla√ß√µes ao longo do tempo √© crucial, nos parece menos explorada. Produtos de IA em v√≠deo frequentemente carregam **tra√ßos din√¢micos at√≠picos**, exibem **inconsist√™ncias temporais sutis**, como falhas em padr√µes de piscar, movimentos de cabe√ßa n√£o naturais, ou transi√ß√µes abruptas entre express√µes faciais, que podem n√£o ser evidentes em um √∫nico quadro, mas se tornam detect√°veis ao analisar a s√©rie temporal de caracter√≠sticas extra√≠das.

### **Fundamenta√ß√£o Te√≥rica**

√â neste ponto que as ferramentas da **Teoria da Informa√ß√£o** e da **An√°lise de Sistemas Din√¢micos Complexos** se mostram particularmente adequadas. A **entropia de Shannon** quantifica a incerteza de um sistema, enquanto a **complexidade estat√≠stica** mede o grau de estrutura e padr√µes, complementando a entropia.

O **Plano Complexidade-Entropia (CECP)**, e sua extens√£o **Multivariada (MvCECP)**, provaram ser eficazes na distin√ß√£o de sistemas com din√¢micas variadas ‚Äî peri√≥dicas, ca√≥ticas e estoc√°sticas ‚Äî ao mapear as caracter√≠sticas de suas s√©ries temporais em um espa√ßo bidimensional.

A **entropia de permuta√ß√£o** (Bandt e Pompe) √© uma medida robusta e computacionalmente eficiente para extrair padr√µes ordinais de s√©ries temporais. O par√¢metro **embedding delay (œÑ)**, por sua vez, permite investigar as s√©ries temporais em diferentes escalas de tempo, revelando din√¢micas ocultas ou an√¥malas.

### **Potencial de Detec√ß√£o**

Acreditamos que a aplica√ß√£o dessas ferramentas aos produtos de IA permitir√° capturar as **"digitais" din√¢micas da manipula√ß√£o** de forma mais precisa. Por exemplo, a suavidade excessiva de certas √°reas manipuladas ou a aus√™ncia de padr√µes ordinais esperados em movimentos faciais podem ser detectadas como desvios em medidas de complexidade-entropia.

Al√©m disso, a **Teoria da Estima√ß√£o Estat√≠stica**, particularmente o **princ√≠pio da m√°xima entropia de Jaynes**, fornecer√° a base formal para inferir as distribui√ß√µes de probabilidade que melhor representam os dados, garantindo que as infer√™ncias sobre a natureza das m√≠dias sint√©ticas sejam as menos preconceituosas e mais objetivas poss√≠veis.

---

## üìã **Protocolo PICOC**

Para estruturar sistematicamente a revis√£o da literatura, utilizaremos o protocolo **PICOC (Population, Intervention, Comparison, Outcomes, Context)**, que fornece um framework robusto para a formula√ß√£o de quest√µes de pesquisa e busca bibliogr√°fica:

### **üéØ Population (Popula√ß√£o)**
- **Imagens e v√≠deos digitais** gerados por algoritmos de intelig√™ncia artificial
- **M√≠dias sint√©ticas** (deepfakes) criadas por GANs, modelos de difus√£o e outras t√©cnicas generativas
- **Datasets de refer√™ncia**: FaceForensics++, Celeb-DF, DFDC, etc.

### **üî¨ Intervention (Interven√ß√£o)**
- **An√°lise de complexidade-entropia** baseada em entropia de permuta√ß√£o
- **Plano Causalidade Entropia-Complexidade (Plano CH)**
- **Extra√ß√£o de features estat√≠sticas** usando padr√µes ordinais bidimensionais
- **Fus√£o com features de Vision Transformers** para detec√ß√£o h√≠brida

### **‚öñÔ∏è Comparison (Compara√ß√£o)**
- **M√©todos tradicionais** baseados em CNNs (ResNet, EfficientNet)
- **Abordagens de an√°lise de artefatos** (ELA, an√°lise espectral)
- **Detectores baseados em ViTs** puros
- **M√©todos ensemble** convencionais

### **üìä Outcomes (Resultados)**
- **Acur√°cia de detec√ß√£o** (AUC-ROC, EER)
- **Capacidade de generaliza√ß√£o** cross-dataset
- **Robustez** a perturba√ß√µes (compress√£o, ru√≠do)
- **Interpretabilidade** dos mecanismos de detec√ß√£o
- **Efici√™ncia computacional**

### **üåç Context (Contexto)**
- **Detec√ß√£o de deepfakes** em ambiente controlado e real
- **Aplica√ß√µes de seguran√ßa da informa√ß√£o**
- **Cen√°rios de forense digital**
- **Mitiga√ß√£o de desinforma√ß√£o**

---

## ‚ùì **Quest√µes de Pesquisa (QA)**

### **üîç Quest√£o Principal (QP)**
**"Como a an√°lise de complexidade-entropia pode aprimorar a detec√ß√£o de m√≠dias sint√©ticas em v√≠deos, superando as limita√ß√µes de generaliza√ß√£o dos m√©todos atuais baseados em deep learning?"**

### **üìã Quest√µes Secund√°rias (QS)**

**QS1:** Quais s√£o as assinaturas estat√≠sticas distintivas de v√≠deos sint√©ticos no espa√ßo complexidade-entropia comparadas √†s de v√≠deos aut√™nticos?

**QS2:** Como a fus√£o de features de complexidade-entropia com representa√ß√µes de Vision Transformers impacta na capacidade de generaliza√ß√£o cross-dataset?

**QS3:** Qual √© a robustez das features baseadas em entropia de permuta√ß√£o contra degrada√ß√µes comuns (compress√£o, ru√≠do) em v√≠deos?

**QS4:** Como os par√¢metros de embedding (dx, dy) influenciam na separabilidade entre classes no Plano CH?

**QS5:** Qual √© o trade-off entre interpretabilidade e performance dos detectores h√≠bridos propostos comparados aos m√©todos estado-da-arte?

**QS6:** Como as caracter√≠sticas temporais dos v√≠deos deepfake se manifestam atrav√©s da an√°lise de s√©ries temporais de complexidade-entropia?

---

## üéØ **Objetivos do Projeto**  

### **üîπ Objetivo Geral**
Desenvolver e validar um **framework h√≠brido e generaliz√°vel** para a detec√ß√£o de v√≠deos deepfake, fundamentado na sinergia entre a an√°lise de complexidade estat√≠stica e a extra√ß√£o de features de aprendizado profundo.

### **üîπ Objetivos Espec√≠ficos**  
1. **Pipeline de Extra√ß√£o:** Implementar um pipeline robusto para a extra√ß√£o das coordenadas (H,C) do Plano CH a partir de frames de v√≠deo, incluindo uma an√°lise de sensibilidade aos par√¢metros de embedding dx e dy.

2. **Mapeamento de Assinaturas:** Mapear e caracterizar as "assinaturas de complexidade" de v√≠deos reais e falsos de m√∫ltiplos datasets (e.g., FaceForensics++, Celeb-DF) no Plano CH, validando empiricamente a Hip√≥tese de Separa√ß√£o.

3. **An√°lise de Robustez:** Avaliar a robustez das features (H,C) a perturba√ß√µes comuns do mundo real, como compress√£o de v√≠deo, adi√ß√£o de ru√≠do e varia√ß√µes de ilumina√ß√£o.

4. **Modelo H√≠brido:** Construir, treinar e validar um modelo h√≠brido que combine F_CH e F_ViT, testando sua capacidade de generaliza√ß√£o contra um modelo baseline.

5. **Interpretabilidade:** Oferecer explica√ß√µes e insights sobre os mecanismos de detec√ß√£o, interpretando como as medidas capturam as anomalias.

---

## üî¨ **Hip√≥teses de Pesquisa**

### **H1 (Hip√≥tese de Separa√ß√£o):**
Imagens geradas por diferentes modelos de IA (e.g., GANs, Modelos de Difus√£o) e imagens aut√™nticas ocupar√£o regi√µes estatisticamente separ√°veis no Plano Causalidade Entropia-Complexidade.

### **H2 (Hip√≥tese de Efici√™ncia Informacional):**
O vetor de features bidimensional F_CH=[H,C], derivado do Plano CH, constitui um estimador estatisticamente mais eficiente da classe da imagem (real vs. falsa) do que features baseadas em artefatos, como as derivadas da An√°lise de N√≠vel de Erro (ELA).

### **H3 (Hip√≥tese de Sinergia H√≠brida):**
Um modelo de classifica√ß√£o que funde as features interpret√°veis do Plano CH (F_CH) com as features de representa√ß√£o global aprendidas por um Vision Transformer (F_ViT) exibir√° desempenho superior em acur√°cia e generaliza√ß√£o.

---

## üõ† **Metodologia Proposta**

### **1Ô∏è‚É£ Pipeline de Extra√ß√£o de Features Estat√≠sticas (F_CH)**
- **Implementa√ß√£o:** Convers√£o de frames para escala de cinza e varredura por janela deslizante de tamanho dx√ódy
- **Par√¢metros:** Investiga√ß√£o de dimens√µes de embedding dx e dy (e.g., 2√ó2, 3√ó2) respeitando (dx‚ãÖdy)!‚â™W‚ãÖH
- **Sa√≠da:** Vetor [H,C] para cada frame, constituindo features de baixa dimens√£o, computacionalmente eficientes e interpret√°veis

### **2Ô∏è‚É£ Pipeline de Extra√ß√£o de Features de Deep Learning (F_ViT)**
- **Arquitetura:** Vision Transformer (ViT) pr√©-treinado (ViT-Base/16) como extrator "congelado"
- **Extra√ß√£o:** Vetor de embedding do token `[CLS]` da √∫ltima camada para formar F_ViT
- **Justificativa:** Complementaridade conceitual entre padr√µes ordinais locais (PE2D) e depend√™ncias globais (ViT)

### **3Ô∏è‚É£ Fus√£o de Features e Classifica√ß√£o**
- **M√©todo:** Concatena√ß√£o simples: F_hybrid = [F_CH, F_ViT]
- **Classificador:** Gradient Boosting (XGBoost/LightGBM) para dados tabulares heterog√™neos
- **Baseline:** Modelo utilizando apenas F_ViT para valida√ß√£o da Hip√≥tese de Sinergia

### **4Ô∏è‚É£ Protocolo Experimental**
- **Datasets:** 
  - Treinamento/Valida√ß√£o: FaceForensics++ (FF++)
  - Teste Zero-Shot: Celeb-DF (v2)
- **M√©tricas:** AUC-ROC, EER (v√≠deo-level), Acur√°cia/Precis√£o/Recall/F1 (frame-level)
- **Robustez:** Degrada√ß√µes controladas (compress√£o JPEG, ru√≠do Gaussiano)

---

## ÔøΩ **Datasets Utilizados**

O projeto incorpora m√∫ltiplos datasets especializados para garantir robustez e generaliza√ß√£o na detec√ß√£o de deepfakes:

### **üóÇÔ∏è Dataset 1: Deepfake and Real Images**
- **Localiza√ß√£o:** `/Datasets/1/Deepfake and real images.zip`
- **Tipo:** Imagens est√°ticas (deepfake vs. reais)
- **Aplica√ß√£o:** Treinamento inicial e valida√ß√£o de features de complexidade-entropia
- **Caracter√≠sticas:** Dataset balanceado para an√°lise de padr√µes ordinais em imagens sint√©ticas

### **üóÇÔ∏è Dataset 2: Detect AI-Generated Faces High-Quality**
- **Localiza√ß√£o:** `/Datasets/2/Detect AI-Generated Faces High-Quality Dataset.zip`
- **Fonte:** Kaggle - `shahzaibshazoo/detect-ai-generated-faces-high-quality-dataset`
- **Tipo:** Faces de alta qualidade geradas por IA
- **Aplica√ß√£o:** Teste de robustez e valida√ß√£o cross-dataset
- **Instala√ß√£o:**
```python
import kagglehub
path = kagglehub.dataset_download("shahzaibshazoo/detect-ai-generated-faces-high-quality-dataset")
```

### **üéØ Datasets de Refer√™ncia Acad√™mica**
Conforme protocolo PICOC, o projeto tamb√©m utiliza datasets consolidados:
- **FaceForensics++:** Dataset principal para treinamento/valida√ß√£o
- **Celeb-DF v2:** Avalia√ß√£o zero-shot de generaliza√ß√£o
- **DFDC:** Valida√ß√£o adicional em cen√°rios desafiadores

---

## üìö **Base Te√≥rica e Artigos Fundamentais**

### **üî¨ Artigos Te√≥ricos de Base**
Localizados em `/docs/artigos/`:

#### **üìÑ Complexity-Entropy Causality Plane as a Complexity.pdf**
- **Refer√™ncia:** Ribeiro, H. V. et al. (2012)
- **Contribui√ß√£o:** Fundamenta√ß√£o te√≥rica do Plano CH para an√°lise bidimensional
- **Aplica√ß√£o:** Base matem√°tica para extra√ß√£o de features F_CH

#### **üìÑ Distinguishing noise from chaos.pdf**
- **Contribui√ß√£o:** Metodologia para separa√ß√£o de din√¢micas determin√≠sticas e estoc√°sticas
- **Aplica√ß√£o:** Valida√ß√£o da Hip√≥tese de Separa√ß√£o (H1)

#### **üìÑ Theory of Statistical Estimation.pdf**
- **Contribui√ß√£o:** Princ√≠pio da m√°xima entropia de Jaynes
- **Aplica√ß√£o:** Infer√™ncia estat√≠stica objetiva sobre m√≠dias sint√©ticas

#### **üìÑ How-to_conduct_a_systematic_literature_review.pdf**
- **Contribui√ß√£o:** Metodologia PICOC para revis√£o sistem√°tica
- **Aplica√ß√£o:** Estrutura√ß√£o da pesquisa bibliogr√°fica

---

## üîç **Protocolo PICOC: Implementa√ß√£o e Resultados**

### **üìã Prepara√ß√£o da Revis√£o Sistem√°tica**
Localizada em `/docs/picoc/preparacao/`:

#### **üéØ Bases de Dados Utilizadas**
- **Web of Science:** Cole√ß√£o Principal (1945-presente) - 9.000+ peri√≥dicos indexados
- **IEEE Xplore:** Biblioteca Digital completa (1988-presente) - 6M+ documentos
- **Scopus (Elsevier):** Base multidisciplinar abrangente
- **ScienceDirect:** 3.800+ peri√≥dicos e 37.000+ t√≠tulos de livros

#### **üìù Artigos Selecionados (25 Principais)**
Conforme lista em `/docs/picoc/preparacao/artigos selecionados`:

**Surveys e Reviews Fundamentais:**
- Khan A.A. (2025): "A survey on multimedia-enabled deepfake detection" - *Discover Computing*
- Kadha V. (2025): "Unravelling Digital Forgeries: A Systematic Survey" - *ACM Computing Surveys*

**M√©todos de An√°lise Temporal:**
- Zhang Y. (2025): "Exploring coordinated motion patterns of facial landmarks" - *Applied Soft Computing*
- Zhu C. (2024): "Deepfake detection via inter-frame inconsistency recomposition" - *Pattern Recognition*

**Abordagens de An√°lise de Frequ√™ncia:**
- Qiusong L. (2025): "Joint spatial-frequency deepfake detection network" - *Applied Intelligence*
- Shi Z. (2025): "Customized Transformer Adapter With Frequency Masking" - *IEEE TIFS*

**M√©todos Baseados em Teoria da Informa√ß√£o:**
- Sheng Z. (2025): "SUMI-IFL: An Information-Theoretic Framework" - *AAAI 2025*
- Sudarsan M. (2025): "LEAD-AI: Lightweight Entropy Analysis" - *SPIE*

### **‚úÖ Artigos Aprovados para Revis√£o**
Localizados em `/docs/picoc/aprovados/1-11/`:
- **11 artigos** selecionados ap√≥s aplica√ß√£o dos crit√©rios de QA
- Cada pasta cont√©m: PDF completo, arquivo .bib, e metadados HTML
- Crit√©rios de aprova√ß√£o baseados nas 7 quest√µes de avalia√ß√£o (Q1-Q7)

---

## ‚ùì **Quest√µes de Avalia√ß√£o (QA) - Refinadas**

### **üìä Crit√©rios de Qualidade dos Estudos**
Baseados em an√°lise em `/docs/picoc/preparacao/perguntas_avaliacao`:

#### **üî¨ Rigor Metodol√≥gico**
**Q1:** O estudo reporta m√©tricas de avalia√ß√£o claras e apropriadas para a tarefa (ex: Acur√°cia, AUC-ROC, EER)?

**Q2:** O estudo utiliza datasets p√∫blicos e bem conhecidos para valida√ß√£o (ex: FaceForensics++, Celeb-DF)?

**Q3:** O m√©todo proposto √© comparado com pelo menos um outro m√©todo de detec√ß√£o j√° existente (baseline)?

#### **üéØ Robustez e Aplicabilidade**
**Q4:** O estudo avalia a robustez do detector contra perturba√ß√µes comuns (ex: compress√£o, ru√≠do, varia√ß√µes de ilumina√ß√£o)?

**Q5:** A metodologia proposta √© descrita com detalhes suficientes para permitir a sua replica√ß√£o?

#### **üìà Credibilidade Cient√≠fica**
**Q6:** Os autores discutem as limita√ß√µes do estudo e as amea√ßas √† validade dos resultados?

**Q7:** Os objetivos da pesquisa, as contribui√ß√µes e as quest√µes de pesquisa do estudo est√£o claramente definidos?

### **üìö Artigos em An√°lise Detalhada (QA)**
Localizados em `/docs/picoc/qa/`:

#### **Surveys e Estado-da-Arte:**
- "A survey on multimedia-enabled deepfake detection state-of-the-art tools and techniques..."
- "Unravelling Digital Forgeries A Systematic Survey on Image Manipulation Detection..."

#### **M√©todos Baseados em Transformers:**
- "Customized Transformer Adapter With Frequency Masking for Deepfake Detection"
- "WaveConViT: Wavelet-Based Convolutional Vision Transformer..."

#### **Abordagens de An√°lise Temporal e Espacial:**
- "Exploring coordinated motion patterns of facial landmarks for deepfake video detection"
- "Joint spatial-frequency deepfake detection network based on dual-domain attention..."

#### **M√©todos Baseados em Teoria da Informa√ß√£o:**
- "LEAD-AI lightweight entropy analysis for distinguishing AI-generated images..."
- "SUMI-IFL An Information-Theoretic Framework for Image Forgery Localization..."

#### **An√°lise de Robustez:**
- "DPL Cross-quality DeepFake Detection via Dual Progressive Learning"
- "Detecting face tampering in videos using deepfake forensics"

---

## ÔøΩüîß **Ambiente de Desenvolvimento**

### **üêç Python com Anaconda**
O projeto utiliza **Python** como linguagem principal, gerenciado atrav√©s do **Anaconda** para garantir reprodutibilidade e isolamento de depend√™ncias.

#### **Instala√ß√£o do Ambiente:**
```bash
# Criar ambiente conda
conda create -n a python=3.9
conda activate deepfake-detection

# Instalar depend√™ncias principais
conda install numpy pandas matplotlib scikit-learn
conda install pytorch torchvision torchaudio -c pytorch
pip install transformers ordpy
```

### **üìä Pacote ordpy**
O projeto utiliza intensivamente o pacote **ordpy** para an√°lise de entropia de permuta√ß√£o e complexidade estat√≠stica.

#### **Sobre o ordpy:**
- **Reposit√≥rio:** [arthurpessa/ordpy](https://github.com/arthurpessa/ordpy)
- **Documenta√ß√£o:** [ordpy.readthedocs.io](https://ordpy.readthedocs.io/)
- **Refer√™ncia:** Pessa, A. A. B., & Ribeiro, H. V. (2021). ordpy: A Python package for data analysis with permutation entropy and ordinal network methods. *Chaos*, 31, 063110.

#### **Funcionalidades Utilizadas:**
- `ordpy.complexity_entropy()` - C√°lculo do Plano Complexidade-Entropia
- `ordpy.permutation_entropy()` - Entropia de permuta√ß√£o para s√©ries temporais e imagens
- `ordpy.two_by_two_patterns()` - Padr√µes ordinais 2√ó2 para an√°lise de imagens
- `ordpy.ordinal_distribution()` - Distribui√ß√µes ordinais para an√°lise estat√≠stica

#### **Instala√ß√£o:**
```bash
pip install ordpy
```

#### **Exemplo de Uso:**
```python
import ordpy
import numpy as np

# An√°lise de complexidade-entropia para imagem
H, C = ordpy.complexity_entropy(image_data, dx=2, dy=2)
print(f"Entropia: {H:.4f}, Complexidade: {C:.4f}")

# Padr√µes ordinais 2x2
patterns = ordpy.two_by_two_patterns(image_data, 
                                   taux=1, tauy=1, 
                                   overlapping=True, 
                                   tie_patterns=True)
```

---

## üìä **Cronograma**

O projeto est√° planejado para execu√ß√£o ao longo de **24 meses**, dividido em quatro fases:

### **üìö Fase 1 (Meses 1-6): Fundamenta√ß√£o e Implementa√ß√£o**
- Revis√£o aprofundada da literatura
- Configura√ß√£o do ambiente computacional (Anaconda + ordpy)
- Implementa√ß√£o dos pipelines F_CH e F_ViT
- Familiariza√ß√£o com datasets

### **üî¨ Fase 2 (Meses 7-12): Experimenta√ß√£o**
- Extra√ß√£o de features nos datasets FF++ e Celeb-DF
- An√°lise de sensibilidade dos par√¢metros PE2D
- Caracteriza√ß√£o das assinaturas de complexidade
- Valida√ß√£o da Hip√≥tese de Separa√ß√£o (H1)

### **ü§ñ Fase 3 (Meses 13-18): Desenvolvimento**
- Desenvolvimento do modelo h√≠brido
- Implementa√ß√£o do modelo baseline
- Treinamento e otimiza√ß√£o
- Valida√ß√£o das hip√≥teses H2 e H3

### **üìä Fase 4 (Meses 19-24): Valida√ß√£o e Documenta√ß√£o**
- Protocolo de valida√ß√£o final
- Testes de generaliza√ß√£o e robustez
- An√°lise dos resultados
- Reda√ß√£o da disserta√ß√£o

---

## üìà **Resultados Esperados**  

- **Valida√ß√£o Emp√≠rica:** Confirma√ß√£o das tr√™s hip√≥teses centrais do projeto
- **Framework Inovador:** Desenvolvimento de um detector h√≠brido fundamentado em teoria
- **Generaliza√ß√£o Superior:** Desempenho robusto em datasets n√£o vistos durante treinamento
- **Interpretabilidade:** Explica√ß√µes claras dos mecanismos de detec√ß√£o
- **Contribui√ß√£o Cient√≠fica:** Publica√ß√µes em confer√™ncias e peri√≥dicos de alto impacto
- **C√≥digo Aberto:** Disponibiliza√ß√£o do framework para a comunidade cient√≠fica

---

## üìö **Refer√™ncias Bibliogr√°ficas**

AGARWAL, S. et al. Detecting face synthesis using convolutional neural networks and image quality assessment. **IEEE Transactions on Information Forensics and Security**, v. 15, p. 3044-3055, 2020.

AFCHAR, D. et al. MesoNet: a Compact Facial Video Forgery Detection Network. In: **IEEE International Workshop on Information Forensics and Security (WIFS)**. Hong Kong: IEEE, 2018. p. 1-7. DOI: [10.1109/WIFS.2018.8630761](https://doi.org/10.1109/WIFS.2018.8630761).

AMERINI, I. et al. Deepfake-o-meter: An open platform for deepfake detection. In: **Proceedings of the 29th ACM International Conference on Multimedia**. Virtual Event: ACM, 2021. p. 103-112. DOI: [10.1145/3474085.3475667](https://doi.org/10.1145/3474085.3475667).

ANDERSON, R. J. **Security Engineering: A Guide to Building Dependable Distributed Systems**. 3. ed. Hoboken: John Wiley & Sons, 2020.

ANTUNES, P. et al. Leveraging ordinal patterns for improved deepfake detection. **Neural Computing and Applications**, v. 34, n. 18, p. 15479-15493, 2022. DOI: [10.1007/s00521-022-07043-5](https://doi.org/10.1007/s00521-022-07043-5).

BANDT, C.; POMPE, B. Permutation entropy: a natural complexity measure for time series. **Physical Review Letters**, v. 88, n. 17, p. 174102, 2002. DOI: [10.1103/PhysRevLett.88.174102](https://doi.org/10.1103/PhysRevLett.88.174102).

BONETTINI, N. et al. Video face manipulation detection through ensemble of CNNs. In: **International Conference on Pattern Recognition (ICPR)**. Milan: IEEE, 2020. p. 5012-5019. DOI: [10.1109/ICPR48806.2021.9412711](https://doi.org/10.1109/ICPR48806.2021.9412711).

BROWN, T. et al. Language models are few-shot learners. In: **Advances in Neural Information Processing Systems**, v. 33, p. 1877-1901, 2020. Dispon√≠vel em: [https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf](https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf). Acesso em: 26 ago. 2025.

CALDELLI, R.; BECARELLI, R.; AMERINI, I. Image origin classification based on social network provenance. **IEEE Transactions on Information Forensics and Security**, v. 12, n. 6, p. 1299-1308, 2017. DOI: [10.1109/TIFS.2017.2656842](https://doi.org/10.1109/TIFS.2017.2656842).

CHEN, S. et al. The eyes tell all: detecting fake face images via the eyes. **IEEE Access**, v. 8, p. 149915-149924, 2020. DOI: [10.1109/ACCESS.2020.3016867](https://doi.org/10.1109/ACCESS.2020.3016867).

CHOLLET, F. Xception: Deep learning with depthwise separable convolutions. In: **Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition**. Honolulu: IEEE, 2017. p. 1251-1258. DOI: [10.1109/CVPR.2017.195](https://doi.org/10.1109/CVPR.2017.195).

DOLHANSKY, B. et al. The DeepFake Detection Challenge (DFDC) Dataset and Benchmark. **arXiv preprint** arXiv:2006.07397, 2020. Dispon√≠vel em: [https://arxiv.org/abs/2006.07397](https://arxiv.org/abs/2006.07397). Acesso em: 26 ago. 2025.

DOSOVITSKIY, A. et al. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In: **International Conference on Learning Representations (ICLR)**. Vienna: OpenReview, 2021. Dispon√≠vel em: [https://openreview.net/forum?id=YicbFdNTTy](https://openreview.net/forum?id=YicbFdNTTy). Acesso em: 26 ago. 2025.

DURALL, R. et al. Watch your up-convolution: CNN based generative deep neural networks are failing to reproduce spectral distributions. In: **Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition**. Seattle: IEEE, 2020. p. 7890-7899. DOI: [10.1109/CVPR42600.2020.00791](https://doi.org/10.1109/CVPR42600.2020.00791).

FRANK, J.; EISENHOFER, T.; SCH√ñNHERR, L. Leveraging frequency analysis for deep fake image recognition. In: **International Conference on Machine Learning**. PMLR, 2020. p. 3247-3258. Dispon√≠vel em: [http://proceedings.mlr.press/v119/frank20a.html](http://proceedings.mlr.press/v119/frank20a.html). Acesso em: 26 ago. 2025.

GOODFELLOW, I. et al. Generative Adversarial Nets. In: **Advances in Neural Information Processing Systems**, v. 27, p. 2672-2680, 2014. Dispon√≠vel em: [https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf). Acesso em: 26 ago. 2025.

GUARNERA, L. et al. Deepfake video detection through optical flow based CNN. In: **Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops**. Seoul: IEEE, 2019. p. 1205-1207. DOI: [10.1109/ICCVW.2019.00152](https://doi.org/10.1109/ICCVW.2019.00152).

HE, K. et al. Deep residual learning for image recognition. In: **Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition**. Las Vegas: IEEE, 2016. p. 770-778. DOI: [10.1109/CVPR.2016.90](https://doi.org/10.1109/CVPR.2016.90).

HEUSEL, M. et al. GANs trained by a two time-scale update rule converge to a local Nash equilibrium. In: **Advances in Neural Information Processing Systems**, v. 30, 2017. Dispon√≠vel em: [https://proceedings.neurips.cc/paper/2017/file/8a1d694707eb0fefe65871369074926d-Paper.pdf](https://proceedings.neurips.cc/paper/2017/file/8a1d694707eb0fefe65871369074926d-Paper.pdf). Acesso em: 26 ago. 2025.

JIANG, L. et al. Celeb-DF: A large-scale challenging dataset for deepfake forensics. In: **Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition**. Seattle: IEEE, 2020. p. 3207-3216. DOI: [10.1109/CVPR42600.2020.00327](https://doi.org/10.1109/CVPR42600.2020.00327).

KARRAS, T. et al. Analyzing and improving the image quality of StyleGAN. In: **Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition**. Seattle: IEEE, 2020. p. 8110-8119. DOI: [10.1109/CVPR42600.2020.00813](https://doi.org/10.1109/CVPR42600.2020.00813).

LI, L. et al. Face X-ray for more general face forgery detection. In: **Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition**. Seattle: IEEE, 2020. p. 5001-5010. DOI: [10.1109/CVPR42600.2020.00505](https://doi.org/10.1109/CVPR42600.2020.00505).

LI, Y. et al. In ictu oculi: Exposing AI generated fake face videos by detecting eye blinking. In: **IEEE International Workshop on Information Forensics and Security (WIFS)**. Hong Kong: IEEE, 2018. p. 1-7. DOI: [10.1109/WIFS.2018.8630787](https://doi.org/10.1109/WIFS.2018.8630787).

LOPEZ-PAZ, D.; OQUAB, M. Revisiting classifier two-sample tests. In: **International Conference on Learning Representations**. Toulon: OpenReview, 2017. Dispon√≠vel em: [https://openreview.net/forum?id=SJkXfE5xx](https://openreview.net/forum?id=SJkXfE5xx). Acesso em: 26 ago. 2025.

## üì¨ **Contato**

üì© **E-mail:** [fl@ic.ufal.br](mailto:fl@ic.ufal.br)  
üîó **LinkedIn:** [linkedin.com/in/fabio-linhares](https://www.linkedin.com/in/fabio-linhares)  
üêô **GitHub:** [github.com/fabio-linhares](https://github.com/fabio-linhares)  
üåê **Site do Projeto:** [fabiolinhares.com.br/ufal/orientacao/preprojeto](https://www.fabiolinhares.com.br/ufal/orientacao/preprojeto/preprojeto.html)

---

**Trabalho de Mestrado - Programa de P√≥s-Gradua√ß√£o em Inform√°tica**  
**Universidade Federal de Alagoas (UFAL)**  
**Orientador:** Prof.¬™ Dr.¬™ Fabiane da Silva Queiroz  
**Ano:** 2025
