Scopus
EXPORT DATE: 25 August 2025

@ARTICLE{Kouritzin2025,
	author = {Kouritzin, Michael A.},
	title = {Markov Observation Models and Deepfakes},
	year = {2025},
	journal = {Mathematics},
	volume = {13},
	number = {13},
	doi = {10.3390/math13132128},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010302044&doi=10.3390%2fmath13132128&partnerID=40&md5=fb1bc4248ca8c63668f25a1c3dbc27ae},
	affiliations = {Department of Mathematical and Statistical Sciences, University of Alberta, Edmonton, T6G 2G1, AB, Canada},
	abstract = {Herein, expanded Hidden Markov Models (HMMs) are considered as potential deepfake generation and detection tools. The most specific model is the HMM, while the most general is the pairwise Markov chain (PMC). In between, the Markov observation model (MOM) is proposed, where the observations form a Markov chain conditionally on the hidden state. An expectation-maximization (EM) analog to the Baum–Welch algorithm is developed to estimate the transition probabilities as well as the initial hidden-state-observation joint distribution for all the models considered. This new EM algorithm also includes a recursive log-likelihood equation so that model selection can be performed (after parameter convergence). Once models have been learnt through the EM algorithm, deepfakes are generated through simulation, while they are detected using the log-likelihood. Our three models were compared empirically in terms of their generative and detective ability. PMC and MOM consistently produced the best deepfake generator and detector, respectively. © 2025 by the author.},
	author_keywords = {Baum–Welch algorithm; deepfake; expectation-maximization; hidden Markov model; Markov observation models; pairwise Markov chain},
	correspondence_address = {M.A. Kouritzin; Department of Mathematical and Statistical Sciences, University of Alberta, Edmonton, T6G 2G1, Canada; email: michaelk@ualberta.ca},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277390},
	language = {English},
	abbrev_source_title = {Mathematics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}